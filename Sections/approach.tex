\chapter{Approach}\label{ch:approach}
% generic intro to Chapter
% \todo{In the end, pass on the Chapter and change model images with something more colourful}
In this Chapter, we will discuss the approach we took to solve the problem of classifying the different types of motor imagery EEG signals.
We will discuss the data collection process, the data augmentation techniques used, the classification model, and the virtual environment used to test the model. 
Finally, we will discuss the framework that has been developed for automating the process of data augmentation, signal classification, and application in the virtual environment.

\section{Data Collection}
We need labelled EEG motor imagery data to develop a classification model.
Initially, we used the Physionet EEG Motor Imagery dataset~\cite{goldberger2000physiobank}, which contains EEG data from 109 subjects performing four motor imagery tasks, and the Weibo Motor Imagery~\cite{yi2014evaluation} dataset, which contains EEG data from 10 subjects performing six motor imagery tasks.
Using the MOABB library~\cite{Aristimunha_Mother_of_all_2023, chevallier2024largest, jayaram2018moabb}, we extracted the EEG data from the datasets and preprocessed them to remove noise and artefacts.

To complete the preprocessing step, the data underwent a series of transformations.
First, the data was resampled to 128Hz to facilitate processing and reduce the computational load.
Next, the data was filtered using a band-pass filter between 0.5Hz and 40Hz to remove noise and artefacts.
The recordings were then segmented into 0.5-second windows for each motor imagery subject and task.
In Table~\ref{tab:datasamples}, we show the datasets used during the project and the number of subjects, tasks, and channels in each dataset.

In the early stages of the project, we started working with the two datasets, Physionet and Weibo. We started by discovering the common channels between the two datasets and reached 58 channels so that the model could be trained on a consistent set of features.

After some tests, we decided to continue working only with the Physionet dataset because it has more subjects.
Moreover, the added value of the Weibo dataset was not significant enough regarding network accuracy to justify the extra complexity and training time required to work with two datasets.

After deciding to continue the project with the Physionet dataset, we did not revert the number of channels to 64, as many literature works have shown that lowering the number of channels can improve the network's performance and reduce the computational load~\cite{faye2022eeg}. Also, the training results were satisfying, and the network could classify the data correctly, meaning that the leftover channels were not significant for the specific classification tasks.

\begin{table}[!htbp]
    \centering
    \scalebox{.8}[1]{
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Dataset Name} & \textbf{Number of Subjects} & \textbf{Number of Tasks} & \textbf{Number of Channels}\\
        \hline
        \hline
        Physionet & 109 & 4 & 64\\
        \hline
        Weibo & 10 & 6 & 60\\
        \hline
        \hline
        Reduced Physionet & 109 & 4 & 58\\
        \hline
    \end{tabular}
    }
    \caption{Base datasets used during the project and the ``Reduced'' final one}\label{tab:datasamples}
\end{table}


\section{Data Augmentation}
Data augmentation is a technique for artificially increasing the size of the training dataset by applying transformations to the original data.
This is done to prevent overfitting and to improve the generalization of the model~\cite{wen2020time}.
In this project, we used data augmentation techniques such as stochastic noise injection and generative adversarial networks (GANs) to augment the EEG data.

The stochastic noise injection technique randomly picks values from a Gaussian distribution. It adds them to an impartially selected dataset sample (Figure~\ref{fig:noise_injection}), while the GANs technique generates new data samples by training a GAN model (Figure~\ref{fig:gan}) on the original data.

Using a tensor filled with random numbers taken from a uniform distribution, the GAN generator creates new data samples that are similar to the original data.
We wrapped the noise injection functions in a callable Python class for interoperability between the GAN model and the noise injection technique.
This way, we can mimic the GAN model's behaviour and use the two solutions interchangeably.

In this project, as we will discuss in the next Chapter (Chapter~\ref{ch:methodology}), we used the noise injection technique and the GAN model to validate the classification model, as the GANs were able to generate new data samples that were similar to the original data.

\begin{figure}[!htbp]
    \centering
    \begin{tikzpicture}[
        squarednode/.style={rectangle, draw=black, very thick, minimum size=5mm},
        ]
        \node[squarednode] (dataset) {Dataset};
        \node (none3) [right=of dataset] {~};
        \node[squarednode] (sample) [right=of none3] {Sample};
        \node (none) [below=of dataset] {~};
        \node (none2) [below=of sample] {~};
        \node (none4) [below=of none] {~};
        \node (none3) [right=of none4] {~};
        \node[squarednode] (noise) [right=of none3] {Noise};
        \node[squarednode] (plus) [right=of none2] {+};
        \node[squarednode] (output) [right=of plus] {Output};

        \draw[->] (dataset) -- node [above] {extract} (sample) ;
        \draw[->] (none4) -- node [above] {generate} (noise) ;
        \draw[->] (sample) -- node [right] {~~add} (plus) ;
        \draw[->] (noise) -- (plus) ;
        \draw[->] (plus) -- (output) ;
    \end{tikzpicture}
    \caption{High-level overview of the Noise Injection pipeline.
    The model takes a dataset as input, extracts a sample, generates noise, adds it to the sample, and finally outputs the augmented sample.}\label{fig:noise_injection}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \begin{tikzpicture}[
        squarednode/.style={rectangle, draw=black, very thick, minimum size=5mm},
        ]
        \node[squarednode] (noise) {Noise};
        \node[squarednode] (generator) [right=of noise] {Generator};
        \node[squarednode] (fake_data) [right=of generator] {Fake Data};
        \node (none) [above=of fake_data] {~};
        \node[squarednode] (real_data) [above=of none] {Real Data};
        \node[squarednode] (discriminator) [right=of none] {Discriminator};
        \node[squarednode, dashed] (loss) [right=of discriminator] {Loss};

        \draw[->] (noise) -- (generator);
        \draw[->] (generator) -- (fake_data);
        \draw[->] (real_data) -- (discriminator);
        \draw[->] (fake_data) -- (discriminator);
        \draw[dashed, ->] (discriminator) -- (loss);
        \draw[dashed, ->] (loss) to[out=-90, in=-90] (generator);
        \draw[dashed, ->] (loss) to[out=90, in=90] (discriminator);
    \end{tikzpicture}
    \caption{High level overview of the GAN model, divided in ``Generator'' and ``Discriminator'' including the models input and output data.}\label{fig:gan}
\end{figure}


\section{Classification Model}
Classification is the process of predicting the class label of a given input data sample.
We took inspiration from the literature review to classify the EEG motor imagery data and used an LSTM neural network based on the one presented in~\cite{sharma_deep_2023}.
We also implemented a Transformer-based model from the same paper, but the hardware requirements were too high for a real-time use case, and the training results did not satisfy the LSMT solution.

LSTM networks are a type of recurrent neural network (RNN) capable of learning long-term dependencies in the data.
Along with the LSTM model (Figure \ref{fig:lstm}), we trained as baseline methods a set of Machine Learning models that included Support Vector Machines (SVM) Linear Discriminant Analysis (LDA) and a Convolutional Neural Network (CNN) (EEGNetV4~\cite{lawhern2018eegnet}).
All the models were trained using the ``Reduced'' Physionet dataset. 
Two different training strategies were used: one in which the model was trained on the original dataset divided by label and another in which the model was trained on the dataset divided by label and subject.
The second strategy was used to perform cross-subject validation and, therefore, to test the model's generalization capabilities.

\begin{figure}[!htbp]
    \centering
    \begin{tikzpicture}[
        squarednode/.style={rectangle, draw=black, very thick, minimum size=5mm},
        ]
        \node[squarednode] (input_data) {Input Data};
        \node[squarednode] (rearrange) [below=of input_data] {Rearrange Data};
        \node[squarednode] (input_layer) [right=of input_data] {Input Layer};
        \node[squarednode] (lstm) [below=of input_layer] {LSTM};
        \node[squarednode] (lstm2) [right=of input_layer] {LSTM};
        \node[squarednode] (output_layer) [right=of lstm] {LSTM Output Filter};
        \node[squarednode] (output) [right=of lstm2] {Output};
        \node[squarednode] (softmax) [right=of output_layer] {Softmax};

        \draw[->] (input_data) -- (rearrange);
        \draw[->] (rearrange) -- (input_layer);
        \draw[->] (input_layer) -- (lstm);
        \draw[->] (lstm) -- (lstm2);
        \draw[->] (lstm2) -- (output_layer);
        \draw[->] (output_layer) -- (output);
        \draw[->] (output) -- (softmax);

    \end{tikzpicture}
    \caption{High-level overview of the LSTM model.
    The model takes the input data, rearranges it, and passes it through the input layer, the LSTM layers, and finally, the output and softmax layers to produce the classification output.}\label{fig:lstm}
\end{figure}

\section{Virtual Environment}
Virtual environments are computer-generated simulations and scenarios that can be used to test and evaluate models in a controlled environment~\cite{ellis1994virtual}.
Since one of the model's most important applications is controlling personal devices to test the classification model, we developed a virtual environment using the Unity game engine. In this environment, the user could control a virtual avatar using their motor imagery EEG signals.

The classification model controls the avatar in the virtual environment. It receives the EEG signals from the headset or the generators and classifies them in real-time.
The classification results were then used to move the avatar in the virtual environment.
The virtual environment was designed to provide feedback to the user, helping them understand the classification results and improve their motor imagery skills.
It is crucial to notice that for simplicity and interoperability, the virtual environment was developed using the Unity game engine~\cite{haas2014history}.
The code was written to be as modular as possible to be easily adapted and maintained, and the Unity prefabs, as shown in Figure~\ref{fig:path_prefab}, were used to create the environment.

On the other hand, the classification model was developed using Python and PyTorch.
Therefore, a WebSocket was developed and used as a communication bridge to allow the two environments to communicate.
The WebSocket was developed using the FastAPI library~\cite{noauthor_tiangolofastapi_nodate}, and it was used to send the classification results from the classification model to the virtual environment.
We selected a WebSocket as a communication method because it is fast and easy to implement. It allows the two environments to communicate in real time or with minimal latency, essential for the user experience when controlling a device in the real world.
Also, thanks to this solution, the virtual environment can be easily replaced with a real device, like a wheelchair, and the classification model can be used to control it in real-time.
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/Approach/path_prefab}
    \caption{Infinite runner modular path prefab, used to generate the infinite path in the virtual environment randomly, the walls at the end of the path tile are removable and have separate colliders to detect the collision of the avatar and trigger the generation of new tiles.}\label{fig:path_prefab}
\end{figure}

\section{The Framework}
To automate the process of data augmentation, model classification and game testing, we developed a framework that could be used to streamline the testing process (Figure~\ref{fig:framework}).
The framework was designed to generate new data or receive data from the EEG headset, classify the data, and then send the classification results to the virtual environment for testing.
The virtual environment would then provide feedback to the user by moving the virtual avatar based on the classification results.
The framework was developed using Python and PyTorch. It was designed to be modular and extensible so that new data augmentation techniques, classification models, and virtual environments could be easily added.
The framework was also designed to be easy to use so researchers and developers could quickly test new ideas and models without worrying about the underlying implementation details.
The framework consists of three main components: the data augmentation module, the classification module, and the communication module.
The data augmentation module generates new data samples using data augmentation techniques, the classification module classifies the data samples using the classification model, and the communication module ends the classification results to other devices.
Currently, the paths to the data augmentation and classification models and the WebSocket address can be specified. This allows the framework to be easily adapted to different models and environments.

\begin{figure}[!htbp]
    \centering
    \begin{tikzpicture}[
        squarednode/.style={rectangle, draw=black, very thick, minimum size=5mm},
        ]
        \node[squarednode] (keyboard) {Keyboard Input};
        \node[squarednode] (data_augmentation) [below=of keyboard] {Data Augmentation};
        \node[squarednode] (classification) [right=of keyboard] {Classification};
        \node[squarednode] (websocket) [below=of classification] {Websocket};
        \node[squarednode] (virtual_environment) [right=of classification] {Virtual Environment};

        \draw[->] (keyboard) -- (data_augmentation);
        \draw[->] (data_augmentation) -- (classification);
        \draw[dashed, ->] (classification) -- (websocket);
        \draw[dashed, ->] (websocket) -- (virtual_environment);
    \end{tikzpicture}
\caption{High-level model of the framework.
The framework uses the data augmentation module to generate new data samples, the classification module to classify the data samples, and the communication module to send the classification results to the virtual environment.}
\label{fig:framework}
\end{figure}

Since the researchers may not have access to an EEG headset or their work may require extensive testing that cannot always be performed in controlled environments, the framework was designed to be used also with keyboard input: by mapping a key to a signal generator, it is possible to simulate the EEG headset input.
Therefore, in Figure~\ref{fig:framework}, the ``Keyboard Input'' triggers the dataset augmentation and simulates the EEG headset input. In contrast, the virtual environment provides feedback to the user and closes the testing loop.