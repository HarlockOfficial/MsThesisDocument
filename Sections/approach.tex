\chapter{Approach}\label{ch:approach}
% generic intro to chapter
In this chapter, we will discuss the approach we took to solve the problem of classifying the different types of motor imagery EEG signals.
We will discuss the data collection process, the data augmentation techniques used, the classification model, and the virtual environment used to test the model. 
Finally, we will discuss the framework that was developed to automate the process of data augmentation, signal classification and application in the virtual environment.

\section{Data Collection}
To develop a classification model, we need a set of labelled EEG motor imagery data.
In the initial development steps, we used the Physionet EEG Motor Imagery dataset \cite{goldberger2000physiobank}, which contains EEG data from 109 subjects performing 4 motor imagery tasks, and the Weibo Motor Imagery \cite{yi2014evaluation} dataset, which contains EEG data from 10 subjects performing 6 motor imagery tasks.
Using the MOABB library \cite{Aristimunha_Mother_of_all_2023, chevallier2024largest, jayaram2018moabb}, we extracted the EEG data from the datasets and preprocessed them to remove noise and artifacts.
The preprocessing steps included resampling the datasets to 128Hz, filtering the data with a band-pass filter between 0.5Hz and 40Hz, selecting the highest quantity of EEG channels that was common between the two datasets, and segmenting the data into 0.5 seconds windows for each motor imagery subject and task.
Is important to notice, that after some tests, we decided to continue working only with the Physionet dataset, because it has a larger number of subjects and the added value of the Weibo dataset was not significant enough in terms of network accuracy to justify the extra complexity and train time of working with two datasets.

\section{Data Augmentation}
Data augmentation is a technique used to artificially increase the size of the training dataset by applying transformations to the original data.
This is done to prevent overfitting and to improve the generalization of the model.
In this project, we used data augmentation techniques such as stochastic noise injection and generative adversarial networks (GANs) to augment the EEG data.
% Fix ``randomly'' repetition
The stochastic noise injection technique randomly picks values from a Gaussian distribution and adds them to a randomly selected dataset sample, while the GANs technique generates new data samples by training a GAN model on the original data.
The GAN generator, using a tensor filled with random number taken from a uniform distribution, creates new data samples that are similar to the original data.
For interoperability between the GAN model and the noise injection technique, we wrapped the noise injection functions in a callable Python class.
This way we can mimick the GAN model's behavior and use the two solutions interchangeably.


\section{Classification Model}
Classification is the process of predicting the class label of a given input data sample.
To classify the EEG motor imagery data we started from the literature review and used a Long Short-Term Memory (LSTM) neural network based on the one presented in \cite{sharma_deep_2023}, we also tried creating a network based on their Transformer one, but it was not possible to train such network with the available hardware resources.
LSTM networks are a type of recurrent neural network (RNN) that are capable of learning long-term dependencies in the data.
Along with the LSTM model, we trained as baseline methods, a set of Machine Learning models, that included Support Vector Machines (SVM) and Linear Discriminant Analysis (LDA), and a Convolutional Neural Network (CNN) (EEGNetV4 \cite{lawhern2018eegnet}).
All the models were trained using the Physionet dataset. 
Two different training strategies were used, one where the model was trained on the original dataset, divided by label, and another where the model was trained on the dataset divided by label and subject.
The second strategy was used to perform cross subject validation, and therefore to test the model's generalization capabilities.

\section{Virtual Environment}
Virtual environments are computer-generated simulations and scenarios that can be used to test and evaluate models in a controlled environment.
Since one of the most important applications of the model is wheelchair (or more generically personal devices) control, to test the classification model, we developed a virtual environment using the Unity game engine where the user could control a virtual avatar using their motor imagery EEG signals.
The avatar presented in the virtual environment was controlled by the classification model, which received the EEG signals from the headset or from the generators and classified them in real-time.
The classification results were then used to move the avatar in the virtual environment.
The virtual environment was designed as feedback for the user, to help them understand the classification results and improve their motor imagery skills.
It is important to notice, that for simplicity and interoperability, the virtual environment was developed using the Unity game engine, but the classification model was developed using Python and PyTorch, so a websocket was developed and used as communication bridge to allow the two environments to communicate.
The websocket was developed using the FastAPI library, and it was used to send the classification results from the classification model to the virtual environment.
We selected a websocket as communication method because it is fast and easy to implement, and it allows the two environments to communicate in real-time or with minimal latency, which is important for the user experience in controlling a device in the real world.
Also, thanks to this solution, the virtual environment can be easily replaced with a real device, like a wheelchair, and the classification model can be used to control it in real-time.

\section{The Framework}
To automate the process of data augmentation, model classification and game testing, we developed a framework that could be used to streamline the testing process.
The framework was designed to either generate new data or receive data from the EEG headset, classify the data, and then send the classification results to the virtual environment for testing.
The virtual environment would then provide feedback to the user by moving the virtual avatar based on the classification results.
The framework was developed using Python and PyTorch, and it was designed to be modular and extensible, so that new data augmentation techniques, classification models, and virtual environments could be easily added.
The framework was also designed to be easy to use, so that researchers and developers could quickly test new ideas and models without having to worry about the underlying implementation details.
The framework consists of three main components: the data augmentation module, the classification module, and the communication module.
The data augmentation module is responsible for generating new data samples using the data augmentation techniques, the classification module is responsible for classifying the data samples using the classification model, and the communication module is responsible for sending the classification results to other devices.
Currently, it is possible to specify the paths to the data augmentation and classification models, and the websocket address, in this way the framework can be easily adapted to different models and environments.
