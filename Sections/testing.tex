\chapter{Technical Performance}\label{ch:testing}
% Generated data test outcomes.
% how good the training and system are before putting a human in the loop.
Before testing the system on human subjects, we performed a series of tests to evaluate the performance of the system on generated data. 
The tests were designed to evaluate the performance of the system in terms of the following:
\begin{itemize}
    \item Classification accuracy: the capability of the system to correctly classify the input data.
    \item Latency: the classification speed of the system.
    \item Robustness: the tolerance to noise and errors in the input data.
    \item Other performance metrics, such as efficiency and portability, that we could not deeply verify at this project stage.
\end{itemize}
%The chapter is divided into four sections, we will discuss the classification accuracy, which is the capabilty of the system to correctly classify the input data, the latency, wich is the classification speed of the system, and the robustness of the system, which represents the tolerance to noise and errors in the input data, along with other performance metrics, such as efficiency and portability that we could not deeply verify in this stage of the project.
The results of the tests indicate that the system can classify the generated data with high accuracy, at a competitive time, and with low resource usage.
The system can handle errors and noise in the data and should be able to run on most modern hardware platforms.
We will discuss the results of the human study in the next chapter (Chapter~\ref{ch:human_study}).

\section{Classification Accuracy}
% How good the system is at classifying the data.
Classification accuracy measures how well the system can classify the data correctly.
The classification accuracy is calculated as the percentage of correctly classified data points over the total number of data points.
Classification accuracy is an essential metric for evaluating the performance of the system, as it provides an indication of how well the system is able to distinguish between different classes of data.
During the training we computed the training and validation accuracy of the system, the first metric on the train dataset, to verify wether the network was learning, and the second metric on a part of the dataset that was not used for training.
We evaluated the system's classification accuracy with the generated data.
We will compare these results with the classification accuracy of the system on human subjects in the next chapter.

\subsection*{Train and Validation Accuracy}
The training accuracy is the percentage of correctly classified data points over the total number of data points in the training dataset.
During our training, the training accuracy of the system was 71.37\%.
This result indicates that, in most cases, the system can correctly classify the training data.

The validation accuracy is the percentage of correctly classified data points over the total number of data points in the validation dataset.
During our training, the validation accuracy of the system was 47.23\%.
This score is significantly lower than the training accuracy, indicating the system overfitting the training data.
This means that the system cannot generalize well to new data.
This is a common problem in machine learning, and techniques such as regularization, dropout, and data augmentation can address it.

\begin{table}[!htbp]
    \centering
    \begin{tabular}{|c||c|c|c|c|}
        \hline
        & \textbf{Feet} & \textbf{Left Hand} & \textbf{Right Hand} & \textbf{Rest} \\
        \hline
        \hline
        \textbf{Feet} & \textbf{779} & 367 & 259 & 314 \\
        \hline
        \textbf{Left Hand} & 284 & \textbf{1005} & 189 & 258 \\
        \hline
        \textbf{Right Hand} & 356 & 243 & \textbf{840} & 268 \\
        \hline
        \textbf{Rest} & 1474 & 1188 & 1158 & \textbf{3067} \\
        \hline
    \end{tabular}
    \caption{Confusion matrix of the validation dataset.}\label{tab:confusion_matrix}
\end{table}

Apart from the accuracy metric, we also computed the confusion matrix of the validation dataset, which is shown in Table~\ref{tab:confusion_matrix}.
In this table, it is possible to see the number of data points that were classified as each class.
The matrix diagonal represents the number of correctly classified data points, while the off-diagonal elements represent the number of incorrectly classified data points.
From the confusion matrix, it is possible to see that the system can correctly classify most of the data points for each class. Therefore, although the validation accuracy is low, in our opinion, in a real-world scenario, the system would be able to correctly classify most of the data points and, therefore, be useful to the end user in controlling external devices.

\subsection*{Generated Data Accuracy}
Differently from the validation dataset, the classification accuracy of the system on the generated data was 89.15\%.
This result indicates that, in most cases, the system can classify the artificial data even better than the ones provided by the dataset.
The confusion matrix of the generated data is shown in Table~\ref{tab:gan_confusion_matrix}.
From the confusion matrix, it is possible to see that the system can correctly classify most of the data points for each class and that the system can distinguish between different classes of data.
\begin{table}[!htbp]
    \centering
    \begin{tabular}{|c||c|c|c|c|}
        \hline
        & \textbf{Feet} & \textbf{Left Hand} & \textbf{Right Hand} & \textbf{Rest} \\
        \hline
        \hline
        \textbf{Feet} & \textbf{824} & 104 & 38 & 34 \\
        \hline
        \textbf{Left Hand} & 16 & \textbf{961} & 1 & 22 \\
        \hline
        \textbf{Right Hand} & 28 & 51 & \textbf{789} & 132 \\
        \hline
        \textbf{Rest} & 1 & 6 & 1 & \textbf{992} \\
        \hline
    \end{tabular}
    \caption{Confusion matrix of the GAN generated data.}\label{tab:gan_confusion_matrix}
\end{table}


\section{Latency}
% How fast the system is at classifying the data.
The latency measures how fast the system can classify the data.
The latency is calculated as the system's time to classify a data point.
Latency is an important metric for evaluating the system's performance, as it indicates how fast the system can respond to new data and user input.
Since the classification time does not depend on the type of data point received, we tested the system's latency using dataset data.
The system's average latency was 5.70 milliseconds, with a minimum latency of 1.10 milliseconds and a maximum latency of 24.67 milliseconds.

It is important to note that the system used 500 milliseconds of EEG recordings, and, as discussed in~\cite{trafton2014blink}, the average human brain image processing time is between 13 and 80 milliseconds; after that, it will take between 100 and 140 milliseconds to elaborate a motor response.
Therefore, we estimate that the system will require between 600 and 750 milliseconds to process the data and provide a response. This is fairly close to the 500 milliseconds of the EEG recording and, in our opinion, is an acceptable delay for EEG-controlled real-time applications and devices.
Figure~\ref{fig:latency} summarizes the latency results in a real-case scenario.
The figure only shows the system's latency. It does not include the time required to communicate the classification outcome to the device and the time required by the device to respond to the classification outcome.
\begin{figure}[!htbp]
    \scalebox{1.2}[1.2]{
    \begin{tikzpicture}
        % Horizontal line
        \draw[thick] (0,0) -- (7.6625,0);
        \draw[thick, dashed] (7.6625,0) -- (8.15,0);
        \draw[thick, -Triangle] (8.15,0) -- (10,0) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{ms}};
        % \draw[thick, dashed] (9,0) -- (9.5,0);
        % \draw[thick, -Triangle] (9,0) -- (10,0) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{ms}};

        % Start of the timeline
        \draw (0,-0.1) -- (0,0.1) node[font=\scriptsize,below left=3pt and -6pt]{\textbf{0}};
        \node[font=\scriptsize,left=3pt] at (0,0) [anchor=east]{\textbf{Min}};

        % Image Processing Time
        \draw (0.1625, -0.1) -- (0.1625, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{olive}{13}}};
        \fill[purple] (0, 0.2) rectangle (0.1625, 0.4);
        
        % \draw (1, -0.1) -- (1, 0.1) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{\textcolor{red}{80}}};
        % \fill[purple] (0,-0.4) rectangle (1,-0.6);
        
        % Motor Response Time
        \draw (1.4125, -0.1) -- (1.4125, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{olive}{113}}};
        \fill[blue] (0.1625, 0.4) rectangle (1.4125, 0.6);

        % \draw (2.75, -0.1) -- (2.75, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{red}{220}}};
        % \fill[blue] (1,-0.6) rectangle (2.75,-0.8);

        % Motor Response Recording Time
        \draw (7.6625, -0.1) -- (7.6625, 0.1) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{\textcolor{olive}{613}}};
        \fill[red] (1.4125, 0.6) rectangle (7.6625, 0.8);

        % \draw (9, -0.1) -- (9, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{red}{720}}};
        % \fill[red] (2.75,-0.8) rectangle (9,-1);

        % Signal Classification Time
        \draw (8.15, -0.1) -- (8.15, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{olive}{615}}};
        \fill[amethyst] (7.6625, 0.8) rectangle (8.15, 1);

        % \draw (9.5, -0.1) -- (9.5, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{red}{732}}};
        % \fill[amethyst] (9,-1) rectangle (9.5,-1.2);

        % diff curly brace
        % \draw [decorate,decoration={brace,amplitude=5pt}] (8.15, 1) -- (9.5,1) node [anchor=south,midway,above=4pt] {\footnotesize Signal Received by Application};
    \end{tikzpicture}
    }
    \scalebox{1.2}[1.2]{
    \begin{tikzpicture}
            % Horizontal line
            \draw[thick] (0,0) -- (9,0);
            % \draw[thick, dashed] (7.6625,0) -- (8.15,0);
            % \draw[thick] (8.15,0) -- (9,0);
            \draw[thick, dashed] (9,0) -- (9.5,0);
            \draw[thick, -Triangle] (9.5,0) -- (10,0) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{ms}};

            % Start of the timeline
            \draw (0,-0.1) -- (0,0.1) node[font=\scriptsize,below left=3pt and -6pt]{\textbf{0}};
            \node[font=\scriptsize,left=3pt] at (0,0) [anchor=east]{\textbf{Max}};

            % Image Processing Time
            % \draw (0.1625, -0.1) -- (0.1625, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{olive}{13}}};
            % \fill[purple] (0, 0.2) rectangle (0.1625, 0.4);
            
            \draw (1, -0.1) -- (1, 0.1) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{\textcolor{red}{80}}};
            \fill[purple] (0,0.2) rectangle (1,0.4);
            
            % Motor Response Time
            % \draw (1.4125, -0.1) -- (1.4125, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{olive}{113}}};
            % \fill[blue] (0.1625, 0.4) rectangle (1.4125, 0.6);

            \draw (2.75, -0.1) -- (2.75, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{red}{220}}};
            \fill[blue] (1,0.4) rectangle (2.75,0.6);

            % Motor Response Recording Time
            % \draw (7.6625, -0.1) -- (7.6625, 0.1) node[font=\scriptsize,below left=3pt and -8pt]{\textbf{\textcolor{olive}{613}}};
            % \fill[red] (1.4125, 0.6) rectangle (7.6625, 0.8);

            \draw (9, -0.1) -- (9, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{red}{720}}};
            \fill[red] (2.75,0.6) rectangle (9,0.8);

            % Signal Classification Time
            % \draw (8.15, -0.1) -- (8.15, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{olive}{614}}};
            % \fill[amethyst] (7.6625, 0.8) rectangle (8.15, 1);

            \draw (9.5, -0.1) -- (9.5, 0.1) node[font=\scriptsize,below left=3pt and -10pt]{\textbf{\textcolor{red}{745}}};
            \fill[amethyst] (9,0.8) rectangle (9.5,1);

            % diff curly brace
            % \draw [decorate,decoration={brace,amplitude=5pt}] (8.15, 1) -- (9.5,1) node [anchor=south,midway,above=4pt] {\footnotesize Signal Received by Application};    
    \end{tikzpicture}
    }
    \begin{itemize}
        \item \textcolor{purple}{Brain Processing Image Time:} 13-80 ms
        \item \textcolor{blue}{Brain Motor Response Activation Time:} 100-140 ms
        \item \textcolor{red}{BCI Motor Response Recording Time:} 500 ms
        \item \textcolor{amethyst}{Signal Classification Time:} 1.10-24.67 ms
    \end{itemize}
    \caption{Latency of the system in a real case scenario.}\label{fig:latency}
\end{figure}

\section{Robustness}
% How well the system performs in case of errors or noise in the data.
The robustness measures how well the system performs in case of errors or noise in the data.
The robustness is an important metric for evaluating the system's performance, as it indicates how well the system can handle errors and noise in the data.
During the tests, we evaluated the system's robustness by testing the classification of data with different levels of Gaussian noise on the dataset and GAN-generated data.
Since the accuracy, as seen in the previous section, is not an extremely accurate metric, we computed the confusion matrix of the system on the noisy data.
We ran tests with increasing levels of Gaussian noise, with a standard deviation going from 0.0 to 9.9 in steps of 0.1 and a mean of 0.0, and we noticed that the system correctly classifies most of the data points for each class in all cases.
In Figure~\ref{fig:robustness} we show the system's precision on the noisy data.
As it is visible, the precision on GAN-generated data is higher than the one on the dataset data, and the precision decreases as the noise level increases. However, the system can still correctly classify most of the data points for each class, even with a high noise level.
The precision scores were computed using the confusion matrices, of which samples are presented in Tables~\ref{tab:confusion_matrix_gan_noise}~and~\ref{tab:confusion_matrix_dataset_noise}.
For each noise level $x$, we computed a confusion matrix $CM_x$ (Figure~\ref{tab:precision_reference}).
Using the main diagonal of each confusion matrix, we computed the precision as the ratio between the value of that cell and the sum of the values in the row $P_{\_, row}$, and the ratio between the cell value and the related column $P_{\_, col}$, we then averaged the two values $P_{\_}$.
Lastly, the average of all the diagonal averages was computed as final precision score $P_{CM_x}$ (Figure~\ref{fig:precision_formula}).

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/Testing/robustness_plot}
    \caption{Robustness of the system in case of noise in the data.}\label{fig:robustness}
\end{figure}

\begin{figure}[!htbp]
    \centering
    \begin{tabular}{|c||c|c|c|c|}
        \hline
        & \textbf{Feet} & \textbf{Left Hand} & \textbf{Right Hand} & \textbf{Rest} \\
        \hline
        \hline
        \textbf{Feet} & $\alpha$ & $\beta$ & $\gamma$ & $\delta$ \\
        \hline
        \textbf{Left Hand} & $\epsilon$ & $\zeta$ & $\eta$ & $\theta$ \\
        \hline
        \textbf{Right Hand} & $\iota$ & $\kappa$ & $\lambda$ & $\mu$ \\
        \hline
        \textbf{Rest} & $\nu$ & $\xi$ & $\pi$ & $\rho$ \\
        \hline
    \end{tabular}
    \caption{Reference Confision Matrix $CM_x$ for the precision computation.}\label{tab:precision_reference}
    \[
    P_{\alpha,row} = \frac{\alpha}{\alpha + \beta + \gamma + \delta} 
    P_{\alpha,col} = \frac{\alpha}{\alpha + \epsilon + \iota + \nu}
    \]
    \[
    P_{\alpha} = \frac{P_{\alpha,row} + P_{\alpha,col}}{2}
    \]
    \[
    P_{\zeta,row} = \frac{\zeta}{\epsilon + \zeta + \eta + \theta}
    P_{\zeta,col} = \frac{\zeta}{\beta + \zeta + \kappa + \xi}
    \]
    \[
    P_{\zeta} = \frac{P_{\zeta,row} + P_{\zeta,col}}{2}
    \]
    \[
    P_{\lambda,row} = \frac{\lambda}{\gamma + \eta + \lambda + \pi}
    P_{\lambda,col} = \frac{\lambda}{\gamma + \eta + \lambda + \pi}
    \]
    \[
    P_{\lambda} = \frac{P_{\lambda,row} + P_{\lambda,col}}{2}
    \]
    \[
    P_{\rho,row} = \frac{\rho}{\delta + \theta + \mu + \rho}
    P_{\rho,col} = \frac{\rho}{\delta + \theta + \mu + \rho}
    \]
    \[
    P_{\rho} = \frac{P_{\rho,row} + P_{\rho,col}}{2}
    \]
    \[
    P_{CM_x} = \frac{P_{\alpha} + P_{\zeta} + P_{\lambda} + P_{\rho}}{4}
    \]
    \caption{Formula to compute the precision of the system.}\label{fig:precision_formula}
\end{figure}


\begin{table}[!htbp]
    \centering
    \begin{tabular}{|c||c|c|c|c|}
        \hline
		Noise: 0.5 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 286.0 & 64.0 & 650.0 & 0.0 \\
        \hline
        Left Hand & 59.0 & 941.0 & 0.0 & 0.0 \\
        \hline
        Right Hand & 0.0 & 9.0 & 991.0 & 0.0 \\
        \hline
        Rest & 6.0 & 504.0 & 351.0 & 139.0 \\
        \hline
        \hline
        \hline
		Noise: 1.0 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 258.0 & 88.0 & 654.0 & 0.0 \\
        \hline
        Left Hand & 62.0 & 938.0 & 0.0 & 0.0 \\
        \hline
        Right Hand & 2.0 & 9.0 & 980.0 & 9.0 \\
        \hline
        Rest & 12.0 & 377.0 & 429.0 & 182.0 \\
        \hline
        \hline
        \hline
		Noise: 2.0 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 172.0 & 113.0 & 715.0 & 0.0 \\
        \hline
        Left Hand & 87.0 & 910.0 & 3.0 & 0.0 \\
        \hline
        Right Hand & 10.0 & 18.0 & 966.0 & 6.0 \\
        \hline
        Rest & 12.0 & 312.0 & 439.0 & 237.0 \\
        \hline
        \hline
        \hline
		Noise: 5 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 129.0 & 116.0 & 755.0 & 0.0 \\
        \hline
        Left Hand & 124.0 & 874.0 & 2.0 & 0.0 \\
        \hline
        Right Hand & 21.0 & 27.0 & 948.0 & 4.0 \\
        \hline
        Rest & 4.0 & 220.0 & 475.0 & 301.0 \\
        \hline
        \hline
        \hline
		Noise: 9.5 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 109.0 & 132.0 & 758.0 & 1.0 \\
        \hline
        Left Hand & 126.0 & 871.0 & 3.0 & 0.0 \\
        \hline
        Right Hand & 18.0 & 17.0 & 964.0 & 1.0 \\
        \hline
        Rest & 2.0 & 194.0 & 461.0 & 343.0 \\
        \hline
    \end{tabular}
    \caption{Confusion Matrix by Noise Levels with GAN as Input}\label{tab:confusion_matrix_gan_noise}
\end{table}

\begin{table}[!htbp]
    \centering
    \begin{tabular}{|c||c|c|c|c|}
        \hline
		Noise: 0.5 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 1275.0 & 421.0 & 377.0 & 382.0 \\
        \hline
        Left Hand & 216.0 & 1679.0 & 256.0 & 329.0 \\
        \hline
        Right Hand & 279.0 & 275.0 & 1535.0 & 349.0 \\
        \hline
        Rest & 1005.0 & 1586.0 & 1541.0 & 5706.0 \\
        \hline
        \hline
        \hline
		Noise: 1.0 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 1274.0 & 424.0 & 376.0 & 381.0 \\
        \hline
        Left Hand & 216.0 & 1677.0 & 255.0 & 332.0 \\
        \hline
        Right Hand & 275.0 & 268.0 & 1534.0 & 361.0 \\
        \hline
        Rest & 1005.0 & 1586.0 & 1553.0 & 5694.0 \\
        \hline
        \hline
        \hline
		Noise: 2.0 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 1262.0 & 428.0 & 380.0 & 385.0 \\
        \hline
        Left Hand & 208.0 & 1675.0 & 258.0 & 339.0 \\
        \hline
        Right Hand & 274.0 & 265.0 & 1529.0 & 370.0 \\
        \hline
        Rest & 989.0 & 1599.0 & 1509.0 & 5741.0 \\
        \hline
        \hline
        \hline
		Noise: 5.0 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 1153.0 & 437.0 & 413.0 & 452.0 \\
        \hline
        Left Hand & 197.0 & 1639.0 & 267.0 & 377.0 \\
        \hline
        Right Hand & 244.0 & 260.0 & 1522.0 & 412.0 \\
        \hline
        Rest & 925.0 & 1523.0 & 1524.0 & 5866.0 \\
        \hline
        \hline
        \hline
		Noise: 9.5 & Feet & Left Hand & Right Hand & Rest \\
        \hline
        \hline
        Feet & 1007.0 & 422.0 & 421.0 & 605.0 \\
        \hline
        Left Hand & 186.0 & 1525.0 & 266.0 & 503.0 \\
        \hline
        Right Hand & 221.0 & 263.0 & 1375.0 & 579.0 \\
        \hline
        Rest & 818.0 & 1336.0 & 1424.0 & 6260.0 \\
        \hline
    \end{tabular}
    \caption{Confusion Matrix by Noise Level with Dataset as Input}\label{tab:confusion_matrix_dataset_noise}
\end{table}



\section{Other Performance Metrics}
In this section, we will discuss a set of other performance metrics that we consider essential but could not be deeply verified at this project stage.
These metrics include portability, which is a measure of how well the system performs on different platforms, efficiency, which is a measure of how well the system performs in terms of resource usage, and maintainability, which is a measure of how well the system performs in terms of code quality and documentation.

\paragraph{Portability}
% How well the system performs on different platforms.
The portability is a measure of how well the system performs on different platforms.
Portability is an important metric for evaluating the system's performance, as it indicates how well the system can run on different hardware and software platforms.
We could not evaluate the portability during the tests due to the lack of different hardware and software platforms.
However, we believe that the system should be able to run on different platforms. It is written in Python 3.10, based on standard machine learning libraries, and does not require any specialized hardware or software except for the EEG device and the CUDA-enabled GPU.
As we will discuss in the next paragraph, we evaluated the system's hardware requirements, and we believe that the system should be able to run flawlessly on most modern hardware platforms.

\paragraph{Efficiency}
% How well the system performs in terms of resource usage.
Efficiency measures how well the system performs in terms of resource usage.
Efficiency is an important metric for evaluating the system's performance, as it indicates how well the system can use the available resources.
During the tests, we evaluated the system's efficiency by measuring the Floating Point Operations per Second (FLOPS), CPU memory, and GPU (CUDA) memory usage during data classification.

\begin{table}[!htbp]
    \centering
    \begin{tabular}{|c||c|c|c|}
        \hline
        \textbf{Resource} & \textbf{Minimum Usage} & \textbf{Average Usage} & \textbf{Maximum Usage} \\
        \hline
        \hline
        K-FLOPS & 754 & 754 & 754\\
        \hline
        CPU Memory & 30 KB & 47 KB & 90 KB \\
        \hline
        GPU CUDA Memory & 277 KB & 17.7 MB  & 41.3 MB \\
        \hline
    \end{tabular}
    \caption{efficiency of the system in terms of resource usage.}\label{tab:efficiency}
\end{table}
Table~\ref{tab:efficiency} shows the results summary of the tests.
As it is visible, the system requires a low amount of resources, $\le$~755~K-FLOPS, $\approx$~47~KB RAM and $\approx$~18~MB VRAM, and should be able to run on most modern hardware platforms.

\paragraph{Maintainability}
% How well the system performs in terms of code quality and documentation.
Maintainability measures how well the system performs in terms of code quality and documentation.
Maintainability is an important metric for evaluating the system's performance, as it indicates how well the system can be maintained and extended.
We evaluated the system's maintainability during the tests by measuring its code quality and documentation.
The system's code quality was evaluated using the Pylint tool, a static code analysis tool for Python.
The Pylint tool provides a score between 0 and 10, where 0 is the worst and ten is the best.
The code quality of the system was 6.55, which indicates that the system has a moderate code quality and that there is room for improvement.
% Unfortunately, as of now, the system does not have any documentation, and we believe it should be documented to make it easier to maintain and extend.

\section{Performance Discussion}
% Summary of the testing results.
In summary, before testing the system on human subjects, we performed a series of tests to evaluate the system's performance on realistic data.
The tests were designed to evaluate the system's classification accuracy, latency and robustness performance, as well as other important performance indicators like portability, efficiency and maintainability.
The results of the tests indicate that the system can classify the generated data with high accuracy.
The classification is performed competitively, allowing real-time applications with an acceptable delay and error.
The system can handle errors and noise in the data and should be able to run on most modern hardware platforms with low resource usage.
Of course, the system has only been tested on generated data as of now, and further testing is required to evaluate its performance on human subjects.
We will discuss the results of the human study in the next chapter.
