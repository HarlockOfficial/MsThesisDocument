\chapter{Introduction}\label{ch:introduction}
Electroencephalography (EEG) is a non-invasive technique that measures the electrical activity of the brain.
It is used in a variety of applications, including medical diagnosis, neurofeedback, and brain-computer interfaces (BCIs).
BCIs are systems that allow users to interact with computers using only their brain activity.
This can be useful for people with severe motor disabilities, as it allows them to control devices and communicate with others.
There are three classical BCI paradigms: event-related potentials (ERPs), steady-state visual evoked potentials (SSVEPs), and motor imagery (MI).
The project focuses on MI, which is a technique where users imagine moving a part of their body, eg. their hand or foot, to control external devices.
This technique has been used in a variety of applications, including controlling robotic arms~\cite{ang2009clinical}, electronic wheelchairs~\cite{palumbo2021motor}, and writing text~\cite{zhang2018converting}.

In this project, our aim is to develop a BCI system that can classify MI tasks using real time EEG data to control the user's virtual avatar.

State of the art solutions for MI classification use deep learning models, based on convolutional neural networks (CNNs) and recurrent neural networks (RNNs)~\cite{li2022motor}.
These models are trained on large datasets of EEG recordings, and can achieve high classification accuracy.
But don't take into account features that are specific to the user, such as the location of the electrodes on the scalp.
This can lead to poor performance when the model is used with new users, or when the electrodes are moved.
To address this issue, in this project we will also try applying Graph Convolutional Networks (GCNs) to the EEG data.
GCNs are a type of neural network that can take into account the spatial structure of the data, and have been used in a variety of applications, including computer vision and traffic prediction~\cite{zhang2019graph}.

The project will initially use the EEG Motor Imagery Dataset from PhysioNet~\cite{goldberger2000physiobank, schalk2004bci2000}.
This dataset contains EEG recordings from 109 subjects performing MI tasks.
The recordings were made using a 64-channel EEG system, and the dataset includes the location of the electrodes on the scalp.
This will allow comparing the performance of CNNs and GCNs on the same dataset, and to investigate the impact of the spatial structure of the data on the classification accuracy.
Also, the dataset recordings are labeled with the MI task performed by the subjects: rest, imagining the movement of left hand, right hand, both feet, and both hands.
The network will be trained to categorise these imagined gestures which will be used to control the virtual avatar.

The project will be implemented using Python~\cite{10.5555/1593511}, a popular high-level programming language, with PyTorch~\cite{NEURIPS2019_9015} or Tensorflow~\cite{tensorflow2015-whitepaper}, widely used deep learning libraries.
Also, MNE-Python~\cite{larson_2024_10519948, 10.3389/fnins.2013.00267}, an open-source package for exploring, visualizing, and analyzing human neurophysiological data, and Braindecode~\cite{HBM:HBM23730}, an open-source Python toolbox for decoding raw electrophysiological brain data with deep learning models, will be used.
Lastly, the possibility of including Spektral, a Python library for building graph neural networks~\cite{grattarola2020graph}, will be evaluated.

The project will be evaluated using a variety of metrics, including classification accuracy, precision, recall, and F1 score.
The performance of the CNN and GCN models will be compared, and the impact of the spatial structure of the data on the classification accuracy will be investigated.
The project will also be evaluated using a real-time BCI system, where the user's EEG live recordings will be used to control a virtual avatar.

The project will be structured as follows:
\begin{itemize}
    \item \textbf{Literature Review}: A review of the current state of the art in BCI systems, and the use of deep learning models for MI classification.
    \item \textbf{Data Preprocessing}: Preprocessing the EEG data, including filtering, artifact removal, and feature extraction.
    \item \textbf{Model Training}: Training state-of-the-art and custom GCN-based models on the preprocessed EEG data to evaluate their performance.
    \item \textbf{Real-time Single-Player Avatar Control}: Implementing a real-time BCI system, where the user's EEG signals are classified in real time, and used to control a virtual avatar.
    \item \textbf{Conclusion}: A summary of the project, and an evaluation of the performance and results of the CNN and GCN models.
\end{itemize}

The project will be supervised by Profs. Loreti Michele, Vilhj\'almsson Hannes H\"ogni, Quadrini Michela and Del Giudice Nicola, and will be carried out at the University of Camerino, Italy.
\\\\

Following in this document, the literature review is presented in Section~\ref{ch:related_works}, the design of the project is presented in Section~\ref{sec:design}, and an high level draft of the schedule is presented in Section~\ref{ch:schedule}.
