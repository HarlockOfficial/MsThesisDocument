\chapter{Plan for Human Study}\label{ch:human_study}
% evaluation of the model in a real-time scenario with real people
% I really wanted to ``close the loop'' of the evaluation by including the human in it, because I was interested in the interaction between human and the system.
% Technical performances may pose some problems, but I want to get the whole picture.
% later it is possible to iterate over everything to improve.
% Study with eeg cap.

% After the testing phase, we wanted to close the loop by conducting a human study to evaluate the system in a real-time scenario with real people.
% The goal of the study was to evaluate the interaction between the user and the system. 
% We wanted to understand how the user perceived the system and how the system performed in a real-world scenario. 
% Our idea was to conduct a pilot study with a small group of participants, and use the results to improve the system and to plan a larger study in the future.
% Unfortunately, due to time constraints and the complexity involved in arranging remote access and assistance with a high grade EEG cap, we were not able to conduct the pilot study.
% Instead, the following sections, describe the planned pilot study by detailing the study design, the participants selection, the procedure we meant to follow, the game design, the data collection process, the user experience survey we prepared, and discuss the planned pilot study.

After the testing phase, we aimed to close the loop by conducting a comprehensive human study to evaluate the system in a real-time scenario with real people. 
The primary objective of this study was to understand the interaction between the user and the system, focusing on user perception and system performance in a real-world setting. 
Our initial plan was to conduct a pilot study with a small group of participants, which would provide preliminary insights and guide improvements for a more extensive future study.

Unfortunately, due to significant time constraints and the complexities involved in not being able to access and receive assistance with a high-grade EEG cap, we were unable to conduct the pilot study as initially planned. 
Nevertheless, this chapter outlines the detailed plan for the pilot study. 
It includes sections on the study design, participant selection, study procedures, game design, data collection process, user experience survey, and a discussion of the planned pilot study. 
By providing this comprehensive overview, we aim to illustrate the meticulous planning involved and highlight the critical steps needed to successfully conduct this type of research.

\section{Study Design}
% The study was designed to evaluate the system in a real-time scenario with real people.
% The participants were asked to play a simple video game using the system.
% The game was designed to be simple and easy to play to avoid any bias due to the complexity of the game.
% The participants were asked to wear an EEG cap and to perform motor imagery tasks to control the game.
% The study was conducted in a controlled environment, to avoid any external interference.
% The participants were asked to fill out a survey after the study, to evaluate the system and their experience.
The study was meticulously designed to evaluate the system's performance and user interaction in a real-time scenario with real participants. Participants were to be engaged in playing a simple yet specifically designed video game using the system. The game design aimed to minimize biases stemming from game complexity, ensuring that the evaluation focused on the capabilities of the system and user interactions. Participants were required to wear an EEG cap and perform motor imagery tasks to control the game, a setup chosen to assess the system's responsiveness to neural commands in a controlled and replicable environment.

To ensure the validity and reliability of the collected data, the study was to be conducted in a controlled environment free from external interference. This controlled setting was crucial to isolate the variables under study and provide a clear understanding of the system's performance under ideal conditions. Post-study, participants were to complete a detailed survey to gather comprehensive feedback on their experience and the system's performance.

\section{Participants}
% we planned to recruit a small group of participants for the study.
% The participants had to be healthy adults with no history of neurological disorders.
% The participants had to be informed about the study and consented to participate.
The study planned to recruit a carefully selected group of healthy adult participants, ensuring they had no history of neurological disorders that could affect the results. 
Each participant was to be fully informed about the study's purpose, procedures, and potential risks and benefits. 
They were required to provide informed consent before participation, ensuring ethical standards were upheld. 
This careful selection and informed consent process aimed to ensure the reliability of the data and the participants' safety and comfort throughout the study.

\section{Procedure}
% The study was conducted in a controlled environment.
% The participants were asked to wear an EEG cap and to perform motor imagery tasks to control the game.
% The participants were asked to play the game for a fixed amount of time and then to fill out a survey to evaluate the system and their experience.
% The study had to be conducted in a single session, and the participants had to be free to ask questions and to take breaks if needed.
In a controlled environment, the procedure required participants to wear an EEG cap and perform motor imagery tasks to control the game. 
Participants were to play the game for a predetermined duration, providing a sufficient time frame to gather meaningful data on system performance and user interaction.
After gameplay, participants were to complete a detailed survey to evaluate their experience with the system, providing quantitative and qualitative data on user satisfaction and system usability.

The study was designed to be conducted in a single session to minimize participant fatigue and maintain consistency in data collection. 
Participants were allowed to ask questions and take breaks to ensure comfort and compliance. 
This flexibility was crucial to maintaining a high participant engagement and data quality.

\section{Game Design}
% The game was designed to be simple and easy to play.
% The game was a 3D walking simulator where the player controlled a character in a virtual environment.
% The player could control the character by performing motor imagery tasks, such as imagining moving their left hand to move the character left, and imagining moving their right hand to move the character right.
% The game was designed to be challenging but not frustrating, to keep the participants engaged.
The game was a 3D walking simulator where the player controlled a character in a virtual environment by performing motor imagery tasks.
For instance, imagining their left hand would move the character left, and imagining their right hand would move the character right. 
The game was designed to be engaging yet not frustrating, balancing challenge and playability to keep participants motivated and focused.

The simplicity of the game was a deliberate design choice to ensure that the evaluation focused on the ability of the system to interpret neural commands rather than the gaming skills of the participant. 
This approach aimed to create an engaging yet straightforward experience, minimizing potential biases and clearly assessing the system's capabilities in a real-time, interactive scenario.

\section{Data Collection}
% We had to collect data during the study to evaluate the system and the user experience.
% Specifically, we planned on screen recording the game session with the microphone on to capture the participant's interactions with the system and their intentions by asking them to think aloud.
% Also, the pipeline was designed to collect EEG data during various stages of the data collection, preprocessing and classification.
% The collected EEG data was necessary to evaluate the system performance, and the survey data to evaluate the user experience.
% The data had then to be analyzed to identify issues with the system and improve it before conducting more in-depth studies.
Data collection was a critical component of the study, aiming to comprehensively evaluate system performance and user experience. 
The plan included screen recording the game sessions with the microphone on to capture the interactions and verbalized thoughts of the participants, providing a rich source of qualitative data. 
Additionally, EEG data was to be collected during various stages of gameplay, more specifically after the initial data collection, before and after each preprocessing step, and before the classification.

This comprehensive data collection aimed to identify system issues and gather insights to improve the system before more in-depth studies. 
The EEG data was crucial for evaluating the system's responsiveness to neural commands, while the survey data provided insights into user satisfaction and potential areas for improvement. 
The study aimed to provide a holistic system evaluation by combining these data sources.

\section{User Experience Survey}
% We prepared a survey wich leverages a Likert Scale~\cite{likert1932technique} to evaluate the user experience.
% The participants were asked to rate their experience with the system on a scale from 1 to 10, where 1 was very bad and 10 was very good.
% The participants were also asked to provide feedback on the system and to suggest improvements.
% The questions were designed to evaluate the system performance and the user experience.
% And followed the System Usability Scale (SUS)~\cite{brooke1996sus} guidelines and included many questions from the Game Experience Questionnaire~\cite{ijsselsteijn2013game}.
% The survey was designed to be short and easy to fill out, to avoid any bias due to the complexity of the questions.
We prepared a user experience survey utilizing a Likert Scale~\cite{likert1932technique} to evaluate the participants' experiences with the system. 
Participants were asked to rate their experience on a scale from 1 to 10, with 1 being very bad and 10 being very good. 
They were also encouraged to provide feedback and suggest improvements. 
The survey incorporated elements from the System Usability Scale (SUS)~\cite{brooke1996sus} and included questions from the Game Experience Questionnaire~\cite{ijsselsteijn2013game}, ensuring a thorough assessment of both system performance and user experience. 
The survey was designed to be concise and straightforward to minimize participant fatigue and bias.

\section{Pre-Pilot Testing of the Human Study}
Before the pilot study, we conducted pre-pilot research with a single participant.
The pre-pilot study's scope was to verify whether the system could correctly work with an EEG cap and whether it ran on a medium-grade computer.
The participant was not asked to play the game for a fixed amount of time or to complete the survey.
Instead, it was asked to test the classification pipeline, checking the quality of the EEG data received, the performances of the model, and the classification results.
The pre-pilot study was conducted to identify any issues with the system and to improve the system before conducting the pilot study.
We noticed immediately that the system was running flawlessly, the pipeline did not add significant delays, and the EEG data was correctly collected.
The only failure point we discovered was in the classification result; it was not working as expected and only predicted ``right-hand'' movements for all the trials.
We understood that, even if the off-line tests provided valid results. The system seemed to understand and classify EEG data of different subjects correctly; the features identified by the model were not discriminative enough for human inter-subject classification. As done in the state-of-the-art solutions, the system requires finetuning on the specific subject to work properly~\cite{jia2023excellent}.
Thanks to this pre-pilot study experience, we understood that the system was ready to be tested with a larger group of participants, but it required a more in-depth training phase to work correctly.
We look forward to conducting the pilot study after the system has been improved and the model has been finetuned on the specific subjects.

\section{Human Study Discussion}
As part of the project, we designed a pilot human study to evaluate the system in a real-time scenario with real people.
The study was designed to evaluate the interaction between the user and the system, understand how the user perceived the system, and assess how the system performed in a real-world scenario.
Due to time constraints, we were not able to conduct the pilot study. Still, we believe that the study would have provided valuable insights into the system and the user experience and would have helped us improve the system before conducting more in-depth studies.
We were able to complete an initial test, with only one subject, to run the system and collect some data.
The test results were not promising because the features identified by the model were not discriminative enough, and the system requires finetuning on the specific subject to work properly.
With more time and resources, we could have trained the network on user-tailored data, conducted the pilot study, and obtained valuable insights into the system and the user experience. We plan to conduct the study to improve the system and to plan more in-depth studies.