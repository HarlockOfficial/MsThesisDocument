\chapter{Plan for Human Study}\label{ch:human_study}
% evaluation of the model in a realtime scenario with real people
% I really wanted to ``close the loop'' of the evaluation by including the human in it, because I was interested in the interaction between human and the system.
% Technical performances may pose some problems, but I want to get the whole picture.
% later it is possible to iterate over everything to improve.
% Study with eeg cap.

% After the testing phase, we wanted to close the loop by conducting a human study to evaluate the system in a real-time scenario with real people.
% The goal of the study was to evaluate the interaction between the user and the system. 
% We wanted to understand how the user perceived the system and how the system performed in a real-world scenario. 
% Our idea was to conduct a pilot study with a small group of participants, and use the results to improve the system and to plan a larger study in the future.
% Unfortunately, due to time constraints and the complexity involved in arranging remote access and assistance with a high grade EEG cap, we were not able to conduct the pilot study.
% Instead, the following sections, describe the planned pilot study by detailing the study design, the participants selection, the procedure we meant to follow, the game design, the data collection process, the user experience survey we prepared, and discuss the planned pilot study.

After the testing phase, we aimed to close the loop by conducting a comprehensive human study to evaluate the system in a real-time scenario with real people. 
The primary objective of this study was to understand the interaction between the user and the system, focusing on user perception and system performance in a real-world setting. 
Our initial plan was to conduct a pilot study with a small group of participants, which would provide preliminary insights and guide improvements for a more extensive future study.

Unfortunately, due to significant time constraints and the complexities involved in arranging remote access and assistance with a high-grade EEG cap, we were unable to conduct the pilot study as initially planned. 
Nevertheless, this chapter outlines the detailed plan for the pilot study. 
It includes sections on the study design, participant selection, study procedures, game design, data collection process, user experience survey, and a discussion of the planned pilot study. 
By providing this comprehensive overview, we aim to illustrate the meticulous planning involved and highlight the critical steps needed to conduct this type of research successfully.

\section{Study Design}
% The study was designed to evaluate the system in a real-time scenario with real people.
% The participants were asked to play a simple video game using the system.
% The game was designed to be simple and easy to play, to avoid any bias due to the complexity of the game.
% The participants were asked to wear an EEG cap and to perform motor imagery tasks to control the game.
% The study was conducted in a controlled environment, to avoid any external interference.
% The participants were asked to fill out a survey after the study, to evaluate the system and their experience.
The study was meticulously designed to evaluate the system's performance and user interaction in a real-time scenario with real participants. Participants were to be engaged in playing a simple yet specifically designed video game using the system. The game design aimed to minimize biases stemming from game complexity, ensuring that the evaluation focused on the capabilities of the system and user interactions. Participants were required to wear an EEG cap and perform motor imagery tasks to control the game, a setup chosen to assess the system's responsiveness to neural commands in a controlled and replicable environment.

To ensure the validity and reliability of the collected data, the study was to be conducted in a controlled environment free from external interferences. This controlled setting was crucial to isolate the variables under study and provide a clear understanding of the performance of the system under ideal conditions. Post-study, participants were to complete a detailed survey designed to gather comprehensive feedback on their experience and the performance of the system.

\section{Participants}
% Our plan was to recruit a small group of participants for the study.
% The participants had to be all healthy adults, with no history of neurological disorders.
% The participants had to be informed about the study and gave their consent to participate.
The study planned to recruit a carefully selected group of healthy adult participants, ensuring they had no history of neurological disorders that could affect the results. 
Each participant was to be fully informed about the study's purpose, procedures, and potential risks and benefits. 
They were required to provide informed consent before participation, ensuring ethical standards were upheld. 
This careful selection and informed consent process aimed to ensure the reliability of the data and the safety and comfort of the participants throughout the study.

\section{Procedure}
% The study was conducted in a controlled environment.
% The participants were asked to wear an EEG cap and to perform motor imagery tasks to control the game.
% The participants were asked to play the game for a fixed amount of time, and then to fill out a survey to evaluate the system and their experience.
% The study had to be conducted in a single session, and the participants had to be free to ask questions and to take breaks if needed.
Conducted in a controlled environment, the procedure required participants to wear an EEG cap and perform motor imagery tasks to control the game. 
Participants were to play the game for a predetermined duration, providing a sufficient time frame to gather meaningful data on system performance and user interaction.
After gameplay, participants were to complete a detailed survey to evaluate their experience with the system, providing both quantitative and qualitative data on user satisfaction and system usability.

The study was designed to be conducted in a single session to minimize participant fatigue and maintain consistency in data collection. 
Participants were allowed to ask questions and take breaks as needed to ensure their comfort and compliance. 
This flexibility was crucial to maintain a high level of participant engagement and data quality.

\section{Game Design}
% The game was designed to be simple and easy to play.
% The game was a 3D walking simulator, where the player controlled a character in a virtual environment.
% The player could control the character by performing motor imagery tasks, such as imagining moving their left hand to move the character left, and imagining moving their right hand to move the character right.
% The game was designed to be challenging but not frustrating, to keep the participants engaged.
The game was a 3D walking simulator where the player controlled a character in a virtual environment by performing motor imagery tasks.
For instance, imagining moving their left hand would move the character left, and imagining moving their right hand would move the character right. 
The game was designed to be engaging yet not frustrating, balancing challenge and playability to keep participants motivated and focused.

The simplicity of the game was a deliberate design choice to ensure that the evaluation focused on the ability of the system to interpret neural commands rather than the gaming skills of the participant. 
This approach aimed to create an engaging yet straightforward experience, minimizing potential biases and providing a clear assessment of the system's capabilities in a real-time, interactive scenario.

\section{Data Collection}
% We had to collect data during the study to evaluate the system and the user experience.
% Specifically, we planned on screen recording the game session with microphone on to capture the interactions of the participants with the system and their intention by asking them to think aloud.
% Also, the pipeline was designed to collect EEG data during various stages of the data collection, preprocessing and classification.
% The collected EEG data was necessary to evaluate the system performance, and the survey data to evaluate the user experience.
% The data had then to be analyzed to identify issues with the system and improve the system before conducting more in depth studies.
Data collection was a critical component of the study, aiming to evaluate both system performance and user experience comprehensively. 
The plan included screen recording the game sessions with the microphone on to capture the interactions and verbalized thoughts of the participants, providing a rich source of qualitative data. 
Additionally, EEG data was to be collected during various stages of gameplay, more specifically after the initial data collection, before and after each preprocessing step, and before the classification.

This comprehensive data collection aimed to identify system issues and gather insights to improve the system before more in-depth studies. 
The EEG data was crucial for evaluating the system's responsiveness to neural commands, while the survey data provided insights into user satisfaction and potential areas for improvement. 
By combining these data sources, the study aimed to provide a holistic evaluation of the system.

\section{User Experience Survey}
% We prepared a survey wich leverages a Likert Scale~\cite{likert1932technique} to evaluate the user experience.
% The participants were asked to rate their experience with the system on a scale from 1 to 10, where 1 was very bad and 10 was very good.
% The participants were also asked to provide feedback on the system and to suggest improvements.
% The questions were designed to evaluate the system performance and the user experience.
% And followed the System Usability Scale (SUS)~\cite{brooke1996sus} guidelines and included many questions from the Game Experience Questionnaire~\cite{ijsselsteijn2013game}.
% The survey was designed to be short and easy to fill out, to avoid any bias due to the complexity of the questions.
We prepared a user experience survey utilizing a Likert Scale~\cite{likert1932technique} to evaluate the experiences of the participants with the system. 
Participants were asked to rate their experience on a scale from 1 to 10, with 1 being very bad and 10 being very good. 
They were also encouraged to provide feedback and suggest improvements. 
The survey incorporated elements from the System Usability Scale (SUS)~\cite{brooke1996sus} and included questions from the Game Experience Questionnaire~\cite{ijsselsteijn2013game}, ensuring a thorough assessment of both system performance and user experience. 
The survey was designed to be concise and straightforward to minimize participant fatigue and bias.

\section{Pre-Pilot Testing of the Human Study}
Before conducting the pilot study, we conducted a pre-pilot study with a single participant.
The scope of the pre-pilot study was to verify wether the system was able to correctly work with an EEG cap and to run on a medium-grade computer.
The participant was not asked to play the game for a fixed amount of time, or to fill out the survey.
Instead, it was asked to test the classification pipeline, checking the quality of the EEG data received, the performances of the model, and the classification results.
The pre-pilot study was conducted to identify any issues with the system and to improve the system before conducting the pilot study.
We noticed immediately that the system was running flawlessly, the pipeline did not add significant delays, and the EEG data was correctly collected.
The only failure point we discovered was in the classification result; it was not working as expected and only predicted ``right-hand'' movements for all the trials.
We understood that, even if the off-line tests provided valid results and the system seemed to correctly understand and classify EEG data of different subjects, the features identified by the model were not discriminative enough for human inter-subject classification, and as done in the state of the art solutions, the system requires finetuning on the specific subject to work properly~\cite{jia2023excellent}.
Thanks to this pre-pilot study experience, we understood that the system was ready to be tested with a larger group of participants, but it required a more in-depth training phase to work properly.
We look forward to conducting the pilot study in the future after the system has been improved and the model has been finetuned on the specific subjects.

\section{Pilot Study Discussion}
As part of the project, we planned and designed a pilot human study to evaluate the system in a real-time scenario with real people.
The study was designed to evaluate the interaction between the user and the system, and to understand how the user perceived the system and how the system performed in a real-world scenario.
We were not able to conduct the pilot study due to time constraints, but we believe that the study would have provided valuable insights into the system and the user experience, and would have helped us to improve the system before conducting more in depth studies in the future.
We were able to complete an initial test, with only one subject, to run the system and collect some data.
The results of the test were not promising, because the feature identified by the model were not discriminative enough and the system requires finetuning on the specific subject to work properly.
We believe that with more time and resources, we could have trained the network on user-tailored data, conducted the pilot study and obtained valuable insights of the system and the user experience, and we plan to conduct the study in the future to improve the system and to plan more in depth studies.